'use strict';

var mlMatrix = require('ml-matrix');

/**
 *
 * @private
 * @param {Array of arrays} collection
 */
function sortCollectionSet(collection) {
  let objectCollection = collection
    .map((value, index) => {
      let key = BigInt(0);
      value.forEach((item) => (key |= BigInt(1) << BigInt(item)));
      return { value, index, key };
    })
    .sort((a, b) => {
      if (a.key - b.key < 0) return -1;
      return 1;
    });

  let sorted = [];
  let indices = [];

  let key;
  for (let set of objectCollection) {
    if (set.key !== key) {
      key = set.key;
      indices.push([]);
      sorted.push(set.value);
    }
    indices[indices.length - 1].push(set.index);
  }

  let result = {
    values: sorted,
    indices,
  };
  return result;
}

/**
 * (Combinatorial Subspace Least Squares) - subfunction for the FC-NNLS
 * @private
 * @param {Matrix} XtX
 * @param {Matrix} XtY
 * @param {Array} Pset
 * @param {Numbers} l
 * @param {Numbers} p
 */
function cssls(XtX, XtY, Pset, l, p) {
  // Solves the set of equation XtX*K = XtY for the variables in Pset
  // if XtX (or XtX(vars,vars)) is singular, performs the svd and find pseudoinverse, otherwise (even if ill-conditioned) finds inverse with LU decomposition and solves the set of equation
  // it is consistent with matlab results for ill-conditioned matrices (at least consistent with test 'ill-conditionned square X rank 2, Y 3x1' in cssls.test)

  let K = mlMatrix.Matrix.zeros(l, p);
  if (Pset === null) {
    let choXtX = new mlMatrix.CholeskyDecomposition(XtX);
    if (choXtX.isPositiveDefinite() === true) {
      K = choXtX.solve(XtY);
    } else {
      let luXtX = new mlMatrix.LuDecomposition(XtX);
      if (luXtX.isSingular() === false) {
        K = luXtX.solve(mlMatrix.Matrix.eye(l)).mmul(XtY);
      } else {
        K = mlMatrix.solve(XtX, XtY, true);
      }
    }
  } else {
    let { values: sortedPset, indices: sortedEset } = sortCollectionSet(Pset);
    if (
      sortedPset.length === 1 &&
      sortedPset[0].length === 0 &&
      sortedEset[0].length === p
    ) {
      return K;
    } else if (
      sortedPset.length === 1 &&
      sortedPset[0].length === l &&
      sortedEset[0].length === p
    ) {
      let choXtX = new mlMatrix.CholeskyDecomposition(XtX);
      if (choXtX.isPositiveDefinite() === true) {
        K = choXtX.solve(XtY);
      } else {
        let luXtX = new mlMatrix.LuDecomposition(XtX);
        if (luXtX.isSingular() === false) {
          K = luXtX.solve(mlMatrix.Matrix.eye(l)).mmul(XtY);
        } else {
          K = mlMatrix.solve(XtX, XtY, true);
        }
      }
    } else {
      for (let k = 0; k < sortedPset.length; k++) {
        let cols2Solve = sortedEset[k];
        let vars = sortedPset[k];
        let L;
        let choXtX = new mlMatrix.CholeskyDecomposition(XtX.selection(vars, vars));
        if (choXtX.isPositiveDefinite() === true) {
          L = choXtX.solve(XtY.selection(vars, cols2Solve));
        } else {
          let luXtX = new mlMatrix.LuDecomposition(XtX.selection(vars, vars));
          if (luXtX.isSingular() === false) {
            L = luXtX
              .solve(mlMatrix.Matrix.eye(vars.length))
              .mmul(XtY.selection(vars, cols2Solve));
          } else {
            L = mlMatrix.solve(
              XtX.selection(vars, vars),
              XtY.selection(vars, cols2Solve),
              true,
            );
          }
        }
        for (let i = 0; i < L.rows; i++) {
          for (let j = 0; j < L.columns; j++) {
            K.set(vars[i], cols2Solve[j], L.get(i, j));
          }
        }
      }
    }
  }
  return K;
}

function initialisation(X, Y) {
  let n = X.rows;
  let l = X.columns;
  let p = Y.columns;
  let iter = 0;

  if (Y.rows !== n) throw new Error('ERROR: matrix size not compatible');

  let W = mlMatrix.Matrix.zeros(l, p);

  // precomputes part of pseudoinverse
  let XtX = X.transpose().mmul(X);
  let XtY = X.transpose().mmul(Y);

  let K = cssls(XtX, XtY, null, l, p); // K is lxp
  let Pset = [];
  for (let j = 0; j < p; j++) {
    Pset[j] = [];
    for (let i = 0; i < l; i++) {
      if (K.get(i, j) > 0) {
        Pset[j].push(i);
      } else {
        K.set(i, j, 0);
      } //This is our initial solution, it's the solution found by overwriting the unconstrained least square solution
    }
  }
  let Fset = [];
  for (let j = 0; j < p; j++) {
    if (Pset[j].length !== l) {
      Fset.push(j);
    }
  }

  let D = K.clone();

  return { n, l, p, iter, W, XtX, XtY, K, Pset, Fset, D };
}

/**
 * Computes the set difference A\B
 * @private
 * @param {A} set A as an array
 * @param {B} set B as an array
 */
function setDifference(A, B) {
  let C = [];
  for (let i of A) {
    if (!B.includes(i)) C.push(i);
  }
  return C;
}

// Makes sure the solution has converged
function optimality(
  iter,
  maxIter,
  XtX,
  XtY,
  Fset,
  Pset,
  W,
  K,
  l,
  p,
  D,
  gradientTolerance = 1e-5,
) {
  if (iter === maxIter) {
    throw new Error('Maximum number of iterations exceeded');
  }

  // Check solution for optimality
  let V = XtY.subMatrixColumn(Fset).subtract(XtX.mmul(K.subMatrixColumn(Fset)));
  for (let j = 0; j < Fset.length; j++) {
    W.setColumn(Fset[j], V.subMatrixColumn([j]));
  }
  let Jset = [];
  let fullSet = [];
  for (let i = 0; i < l; i++) {
    fullSet.push(i);
  }
  for (let j = 0; j < Fset.length; j++) {
    let notPset = setDifference(fullSet, Pset[Fset[j]]);
    if (notPset.length === 0) {
      Jset.push(Fset[j]);
    } else if (W.selection(notPset, [Fset[j]]).max() <= gradientTolerance) {
      // previously gradient tolerance was 0 and this leads to convergence problems
      Jset.push(Fset[j]);
    }
  }
  Fset = setDifference(Fset, Jset);

  // For non-optimal solutions, add the appropriate variables to Pset
  if (Fset.length !== 0) {
    for (let j = 0; j < Fset.length; j++) {
      for (let i = 0; i < l; i++) {
        if (Pset[Fset[j]].includes(i)) W.set(i, Fset[j], -Infinity);
      }
      Pset[Fset[j]].push(W.subMatrixColumn(Fset).maxColumnIndex(j)[0]);
    }
    for (let j = 0; j < Fset.length; j++) {
      D.setColumn(Fset[j], K.getColumn(Fset[j]));
    }
  }
  for (let j = 0; j < p; j++) {
    Pset[j].sort((a, b) => a - b);
  }
  return { Pset, Fset, W };
}

/**
 * Returns a new array based on extraction of specific indices of an array
 * @private
 * @param {Array} vector
 * @param {Array} indices
 */
function selection(vector, indices) {
  let u = []; //new Float64Array(indices.length);
  for (let i = 0; i < indices.length; i++) {
    u[i] = vector[indices[i]];
  }
  return u;
}

/**
 * Fast Combinatorial Non-negative Least Squares with multiple Right Hand Side
 * @param {Matrix|number[][]} X
 * @param {Matrix|number[][]} Y
 * @param {object} [options={}]
 * @param {number} [options.maxIterations] if empty maxIterations is set at 3 times the number of columns of X
 * @param {number} [options.gradientTolerance] Control over the optimality of the solution; applied over the largest gradient value of all.
 * @returns {Matrix} K
 */
function fcnnls(X, Y, options = {}) {
  X = mlMatrix.Matrix.checkMatrix(X);
  Y = mlMatrix.Matrix.checkMatrix(Y);
  let { l, p, iter, W, XtX, XtY, K, Pset, Fset, D } = initialisation(X, Y);
  const { maxIterations = X.columns * 3, gradientTolerance = 1e-5 } = options;

  // Active set algorithm for NNLS main loop
  while (Fset.length > 0) {
    // Solves for the passive variables (uses subroutine below)
    let L = cssls(
      XtX,
      XtY.subMatrixColumn(Fset),
      selection(Pset, Fset),
      l,
      Fset.length,
    );
    for (let i = 0; i < l; i++) {
      for (let j = 0; j < Fset.length; j++) {
        K.set(i, Fset[j], L.get(i, j));
      }
    }

    // Finds any infeasible solutions
    let infeasIndex = [];
    for (let j = 0; j < Fset.length; j++) {
      for (let i = 0; i < l; i++) {
        if (L.get(i, j) < 0) {
          infeasIndex.push(j);
          break;
        }
      }
    }
    let Hset = selection(Fset, infeasIndex);

    // Makes infeasible solutions feasible (standard NNLS inner loop)
    if (Hset.length > 0) {
      let m = Hset.length;
      let alpha = mlMatrix.Matrix.ones(l, m);

      while (m > 0 && iter < maxIterations) {
        iter++;

        alpha.mul(Infinity);

        // Finds indices of negative variables in passive set
        let hRowColIdx = [[], []]; // Indexes work in pairs, each pair reprensents a single element, first array is row index, second array is column index
        let negRowColIdx = [[], []]; // Same as before
        for (let j = 0; j < m; j++) {
          for (let i = 0; i < Pset[Hset[j]].length; i++) {
            if (K.get(Pset[Hset[j]][i], Hset[j]) < 0) {
              hRowColIdx[0].push(Pset[Hset[j]][i]); // i
              hRowColIdx[1].push(j);
              negRowColIdx[0].push(Pset[Hset[j]][i]); // i
              negRowColIdx[1].push(Hset[j]);
            } // Compared to matlab, here we keep the row/column indexing (we are not taking the linear indexing)
          }
        }

        for (let k = 0; k < hRowColIdx[0].length; k++) {
          // could be hRowColIdx[1].length as well
          alpha.set(
            hRowColIdx[0][k],
            hRowColIdx[1][k],
            D.get(negRowColIdx[0][k], negRowColIdx[1][k]) /
              (D.get(negRowColIdx[0][k], negRowColIdx[1][k]) -
                K.get(negRowColIdx[0][k], negRowColIdx[1][k])),
          );
        }

        let alphaMin = [];
        let minIdx = [];
        for (let j = 0; j < m; j++) {
          alphaMin[j] = alpha.minColumn(j);
          minIdx[j] = alpha.minColumnIndex(j)[0];
        }

        alphaMin = mlMatrix.Matrix.rowVector(alphaMin);
        for (let i = 0; i < l; i++) {
          alpha.setSubMatrix(alphaMin, i, 0);
        }

        let E = new mlMatrix.Matrix(l, m);
        E = D.subMatrixColumn(Hset).subtract(
          alpha
            .subMatrix(0, l - 1, 0, m - 1)
            .mul(D.subMatrixColumn(Hset).subtract(K.subMatrixColumn(Hset))),
        );
        for (let j = 0; j < m; j++) {
          D.setColumn(Hset[j], E.subMatrixColumn([j]));
        }

        let idx2zero = [minIdx, Hset];
        for (let k = 0; k < m; k++) {
          D.set(idx2zero[0][k], idx2zero[1][k], 0);
        }

        for (let j = 0; j < m; j++) {
          Pset[Hset[j]].splice(
            Pset[Hset[j]].findIndex((item) => item === minIdx[j]),
            1,
          );
        }

        L = cssls(XtX, XtY.subMatrixColumn(Hset), selection(Pset, Hset), l, m);
        for (let j = 0; j < m; j++) {
          K.setColumn(Hset[j], L.subMatrixColumn([j]));
        }

        Hset = [];
        for (let j = 0; j < K.columns; j++) {
          for (let i = 0; i < l; i++) {
            if (K.get(i, j) < 0) {
              Hset.push(j);

              break;
            }
          }
        }
        m = Hset.length;
      }
    }

    let newParam = optimality(
      iter,
      maxIterations,
      XtX,
      XtY,
      Fset,
      Pset,
      W,
      K,
      l,
      p,
      D,
      gradientTolerance,
    );
    Pset = newParam.Pset;
    Fset = newParam.Fset;
    W = newParam.W;
  }

  return K;
}

/**
 * Fast Combinatorial Non-negative Least Squares with single Right Hand Side
 * @param {Matrix|number[][]} X
 * @param {number[]} y
 * @param {object} [options={}]
 * @param {number} [options.maxIterations] if true or empty maxIterations is set at 3 times the number of columns of X
 * @param {number} [options.gradientTolerance] Control over the optimality of the solution; applied over the largest gradient value of all.
 * @returns {Array} k
 */
function fcnnlsVector(X, y, options = {}) {
  if (Array.isArray(y) === false) {
    throw new TypeError('y must be a 1D Array');
  }
  let Y = mlMatrix.Matrix.columnVector(y);
  let K = fcnnls(X, Y, options);
  let k = K.to1DArray();
  return k;
}

exports.fcnnls = fcnnls;
exports.fcnnlsVector = fcnnlsVector;
