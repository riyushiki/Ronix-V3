'use strict';

Object.defineProperty(exports, '__esModule', { value: true });

function _interopDefault (ex) { return (ex && (typeof ex === 'object') && 'default' in ex) ? ex['default'] : ex; }

var Matrix = require('ml-matrix');
var Matrix__default = _interopDefault(Matrix);
var ConfusionMatrix = _interopDefault(require('ml-confusion-matrix'));
var mlCrossValidation = require('ml-cross-validation');

/**
 * @private
 * Function that given vector, returns its norm
 * @param {Vector} X
 * @return {number} Norm of the vector
 */
function norm(X) {
  return Math.sqrt(
    X.clone()
      .apply(pow2array)
      .sum(),
  );
}

/**
 * @private
 * Function that pow 2 each element of a Matrix or a Vector,
 * used in the apply method of the Matrix object
 * @param {number} i - index i.
 * @param {number} j - index j.
 * @return {Matrix} The Matrix object modified at the index i, j.
 * */
function pow2array(i, j) {
  this.set(i, j, this.get(i, j) ** 2);
}

/**
 * @private
 * Function that initialize an array of matrices.
 * @param {Array} array
 * @param {boolean} isMatrix
 * @return {Array} array with the matrices initialized.
 */
function initializeMatrices(array, isMatrix) {
  if (isMatrix) {
    for (let i = 0; i < array.length; ++i) {
      for (let j = 0; j < array[i].length; ++j) {
        let elem = array[i][j];
        array[i][j] = elem !== null ? new Matrix__default(array[i][j]) : undefined;
      }
    }
  } else {
    for (let i = 0; i < array.length; ++i) {
      array[i] = new Matrix__default(array[i]);
    }
  }

  return array;
}

/**
 * @class PLS
 */
class PLS {
  /**
   * Constructor for Partial Least Squares (PLS)
   * @param {object} options
   * @param {number} [options.latentVectors] - Number of latent vector to get (if the algorithm doesn't find a good model below the tolerance)
   * @param {number} [options.tolerance=1e-5]
   * @param {boolean} [options.scale=true] - rescale dataset using mean.
   * @param {object} model - for load purposes.
   */
  constructor(options, model) {
    if (options === true) {
      this.meanX = model.meanX;
      this.stdDevX = model.stdDevX;
      this.meanY = model.meanY;
      this.stdDevY = model.stdDevY;
      this.PBQ = Matrix__default.checkMatrix(model.PBQ);
      this.R2X = model.R2X;
      this.scale = model.scale;
      this.scaleMethod = model.scaleMethod;
      this.tolerance = model.tolerance;
    } else {
      let { tolerance = 1e-5, scale = true } = options;
      this.tolerance = tolerance;
      this.scale = scale;
      this.latentVectors = options.latentVectors;
    }
  }

  /**
   * Fits the model with the given data and predictions, in this function is calculated the
   * following outputs:
   *
   * T - Score matrix of X
   * P - Loading matrix of X
   * U - Score matrix of Y
   * Q - Loading matrix of Y
   * B - Matrix of regression coefficient
   * W - Weight matrix of X
   *
   * @param {Matrix|Array} trainingSet
   * @param {Matrix|Array} trainingValues
   */
  train(trainingSet, trainingValues) {
    trainingSet = Matrix__default.checkMatrix(trainingSet);
    trainingValues = Matrix__default.checkMatrix(trainingValues);

    if (trainingSet.length !== trainingValues.length) {
      throw new RangeError(
        'The number of X rows must be equal to the number of Y rows',
      );
    }

    this.meanX = trainingSet.mean('column');
    this.stdDevX = trainingSet.standardDeviation('column', {
      mean: this.meanX,
      unbiased: true,
    });
    this.meanY = trainingValues.mean('column');
    this.stdDevY = trainingValues.standardDeviation('column', {
      mean: this.meanY,
      unbiased: true,
    });

    if (this.scale) {
      trainingSet = trainingSet
        .clone()
        .subRowVector(this.meanX)
        .divRowVector(this.stdDevX);
      trainingValues = trainingValues
        .clone()
        .subRowVector(this.meanY)
        .divRowVector(this.stdDevY);
    }

    if (this.latentVectors === undefined) {
      this.latentVectors = Math.min(trainingSet.rows - 1, trainingSet.columns);
    }

    let rx = trainingSet.rows;
    let cx = trainingSet.columns;
    let ry = trainingValues.rows;
    let cy = trainingValues.columns;

    let ssqXcal = trainingSet
      .clone()
      .mul(trainingSet)
      .sum(); // for the rÂ²
    let sumOfSquaresY = trainingValues
      .clone()
      .mul(trainingValues)
      .sum();

    let tolerance = this.tolerance;
    let n = this.latentVectors;
    let T = Matrix__default.zeros(rx, n);
    let P = Matrix__default.zeros(cx, n);
    let U = Matrix__default.zeros(ry, n);
    let Q = Matrix__default.zeros(cy, n);
    let B = Matrix__default.zeros(n, n);
    let W = P.clone();
    let k = 0;
    let t;
    let w;
    let q;
    let p;

    while (norm(trainingValues) > tolerance && k < n) {
      let transposeX = trainingSet.transpose();
      let transposeY = trainingValues.transpose();

      let tIndex = maxSumColIndex(trainingSet.clone().mul(trainingSet));
      let uIndex = maxSumColIndex(trainingValues.clone().mul(trainingValues));

      let t1 = trainingSet.getColumnVector(tIndex);
      let u = trainingValues.getColumnVector(uIndex);
      t = Matrix__default.zeros(rx, 1);

      while (norm(t1.clone().sub(t)) > tolerance) {
        w = transposeX.mmul(u);
        w.div(norm(w));
        t = t1;
        t1 = trainingSet.mmul(w);
        q = transposeY.mmul(t1);
        q.div(norm(q));
        u = trainingValues.mmul(q);
      }

      t = t1;
      let num = transposeX.mmul(t);
      let den = t
        .transpose()
        .mmul(t)
        .get(0, 0);
      p = num.div(den);
      let pnorm = norm(p);
      p.div(pnorm);
      t.mul(pnorm);
      w.mul(pnorm);

      num = u.transpose().mmul(t);
      den = t
        .transpose()
        .mmul(t)
        .get(0, 0);
      let b = num.div(den).get(0, 0);
      trainingSet.sub(t.mmul(p.transpose()));
      trainingValues.sub(
        t
          .clone()
          .mul(b)
          .mmul(q.transpose()),
      );

      T.setColumn(k, t);
      P.setColumn(k, p);
      U.setColumn(k, u);
      Q.setColumn(k, q);
      W.setColumn(k, w);

      B.set(k, k, b);
      k++;
    }

    k--;
    T = T.subMatrix(0, T.rows - 1, 0, k);
    P = P.subMatrix(0, P.rows - 1, 0, k);
    U = U.subMatrix(0, U.rows - 1, 0, k);
    Q = Q.subMatrix(0, Q.rows - 1, 0, k);
    W = W.subMatrix(0, W.rows - 1, 0, k);
    B = B.subMatrix(0, k, 0, k);

    this.ssqYcal = sumOfSquaresY;
    this.E = trainingSet;
    this.F = trainingValues;
    this.T = T;
    this.P = P;
    this.U = U;
    this.Q = Q;
    this.W = W;
    this.B = B;
    this.PBQ = P.mmul(B).mmul(Q.transpose());
    this.R2X = t
      .transpose()
      .mmul(t)
      .mmul(p.transpose().mmul(p))
      .div(ssqXcal)
      .get(0, 0);
  }

  /**
   * Predicts the behavior of the given dataset.
   * @param {Matrix|Array} dataset - data to be predicted.
   * @return {Matrix} - predictions of each element of the dataset.
   */
  predict(dataset) {
    let X = Matrix__default.checkMatrix(dataset);
    if (this.scale) {
      X = X.subRowVector(this.meanX).divRowVector(this.stdDevX);
    }
    let Y = X.mmul(this.PBQ);
    Y = Y.mulRowVector(this.stdDevY).addRowVector(this.meanY);
    return Y;
  }

  /**
   * Returns the explained variance on training of the PLS model
   * @return {number}
   */
  getExplainedVariance() {
    return this.R2X;
  }

  /**
   * Export the current model to JSON.
   * @return {object} - Current model.
   */
  toJSON() {
    return {
      name: 'PLS',
      R2X: this.R2X,
      meanX: this.meanX,
      stdDevX: this.stdDevX,
      meanY: this.meanY,
      stdDevY: this.stdDevY,
      PBQ: this.PBQ,
      tolerance: this.tolerance,
      scale: this.scale,
    };
  }

  /**
   * Load a PLS model from a JSON Object
   * @param {object} model
   * @return {PLS} - PLS object from the given model
   */
  static load(model) {
    if (model.name !== 'PLS') {
      throw new RangeError(`Invalid model: ${model.name}`);
    }
    return new PLS(true, model);
  }
}

/**
 * @private
 * Function that returns the index where the sum of each
 * column vector is maximum.
 * @param {Matrix} data
 * @return {number} index of the maximum
 */
function maxSumColIndex(data) {
  return Matrix__default.rowVector(data.sum('column')).maxIndex()[0];
}

/**
 * @class KOPLS
 */
class KOPLS {
  /**
   * Constructor for Kernel-based Orthogonal Projections to Latent Structures (K-OPLS)
   * @param {object} options
   * @param {number} [options.predictiveComponents] - Number of predictive components to use.
   * @param {number} [options.orthogonalComponents] - Number of Y-Orthogonal components.
   * @param {Kernel} [options.kernel] - Kernel object to apply, see [ml-kernel](https://github.com/mljs/kernel).
   * @param {object} model - for load purposes.
   */
  constructor(options, model) {
    if (options === true) {
      this.trainingSet = new Matrix.Matrix(model.trainingSet);
      this.YLoadingMat = new Matrix.Matrix(model.YLoadingMat);
      this.SigmaPow = new Matrix.Matrix(model.SigmaPow);
      this.YScoreMat = new Matrix.Matrix(model.YScoreMat);
      this.predScoreMat = initializeMatrices(model.predScoreMat, false);
      this.YOrthLoadingVec = initializeMatrices(model.YOrthLoadingVec, false);
      this.YOrthEigen = model.YOrthEigen;
      this.YOrthScoreMat = initializeMatrices(model.YOrthScoreMat, false);
      this.toNorm = initializeMatrices(model.toNorm, false);
      this.TURegressionCoeff = initializeMatrices(
        model.TURegressionCoeff,
        false,
      );
      this.kernelX = initializeMatrices(model.kernelX, true);
      this.kernel = model.kernel;
      this.orthogonalComp = model.orthogonalComp;
      this.predictiveComp = model.predictiveComp;
    } else {
      if (options.predictiveComponents === undefined) {
        throw new RangeError('no predictive components found!');
      }
      if (options.orthogonalComponents === undefined) {
        throw new RangeError('no orthogonal components found!');
      }
      if (options.kernel === undefined) {
        throw new RangeError('no kernel found!');
      }

      this.orthogonalComp = options.orthogonalComponents;
      this.predictiveComp = options.predictiveComponents;
      this.kernel = options.kernel;
    }
  }

  /**
   * Train the K-OPLS model with the given training set and labels.
   * @param {Matrix|Array} trainingSet
   * @param {Matrix|Array} trainingValues
   */
  train(trainingSet, trainingValues) {
    trainingSet = Matrix.Matrix.checkMatrix(trainingSet);
    trainingValues = Matrix.Matrix.checkMatrix(trainingValues);

    // to save and compute kernel with the prediction dataset.
    this.trainingSet = trainingSet.clone();

    let kernelX = this.kernel.compute(trainingSet);

    let Identity = Matrix.Matrix.eye(kernelX.rows, kernelX.rows, 1);
    let temp = kernelX;
    kernelX = new Array(this.orthogonalComp + 1);
    for (let i = 0; i < this.orthogonalComp + 1; i++) {
      kernelX[i] = new Array(this.orthogonalComp + 1);
    }
    kernelX[0][0] = temp;

    let result = new Matrix.SingularValueDecomposition(
      trainingValues
        .transpose()
        .mmul(kernelX[0][0])
        .mmul(trainingValues),
      {
        computeLeftSingularVectors: true,
        computeRightSingularVectors: false,
      },
    );
    let YLoadingMat = result.leftSingularVectors;
    let Sigma = result.diagonalMatrix;

    YLoadingMat = YLoadingMat.subMatrix(
      0,
      YLoadingMat.rows - 1,
      0,
      this.predictiveComp - 1,
    );
    Sigma = Sigma.subMatrix(
      0,
      this.predictiveComp - 1,
      0,
      this.predictiveComp - 1,
    );

    let YScoreMat = trainingValues.mmul(YLoadingMat);

    let predScoreMat = new Array(this.orthogonalComp + 1);
    let TURegressionCoeff = new Array(this.orthogonalComp + 1);
    let YOrthScoreMat = new Array(this.orthogonalComp);
    let YOrthLoadingVec = new Array(this.orthogonalComp);
    let YOrthEigen = new Array(this.orthogonalComp);
    let YOrthScoreNorm = new Array(this.orthogonalComp);

    let SigmaPow = Matrix.Matrix.pow(Sigma, -0.5);
    // to avoid errors, check infinity
    SigmaPow.apply(function(i, j) {
      if (this.get(i, j) === Infinity) {
        this.set(i, j, 0);
      }
    });

    for (let i = 0; i < this.orthogonalComp; ++i) {
      predScoreMat[i] = kernelX[0][i]
        .transpose()
        .mmul(YScoreMat)
        .mmul(SigmaPow);

      let TpiPrime = predScoreMat[i].transpose();
      TURegressionCoeff[i] = Matrix.inverse(TpiPrime.mmul(predScoreMat[i]))
        .mmul(TpiPrime)
        .mmul(YScoreMat);

      result = new Matrix.SingularValueDecomposition(
        TpiPrime.mmul(
          Matrix.Matrix.sub(kernelX[i][i], predScoreMat[i].mmul(TpiPrime)),
        ).mmul(predScoreMat[i]),
        {
          computeLeftSingularVectors: true,
          computeRightSingularVectors: false,
        },
      );
      let CoTemp = result.leftSingularVectors;
      let SoTemp = result.diagonalMatrix;

      YOrthLoadingVec[i] = CoTemp.subMatrix(0, CoTemp.rows - 1, 0, 0);
      YOrthEigen[i] = SoTemp.get(0, 0);

      YOrthScoreMat[i] = Matrix.Matrix.sub(
        kernelX[i][i],
        predScoreMat[i].mmul(TpiPrime),
      )
        .mmul(predScoreMat[i])
        .mmul(YOrthLoadingVec[i])
        .mul(Math.pow(YOrthEigen[i], -0.5));

      let toiPrime = YOrthScoreMat[i].transpose();
      YOrthScoreNorm[i] = Matrix.Matrix.sqrt(toiPrime.mmul(YOrthScoreMat[i]));

      YOrthScoreMat[i] = YOrthScoreMat[i].divRowVector(YOrthScoreNorm[i]);

      let ITo = Matrix.Matrix.sub(
        Identity,
        YOrthScoreMat[i].mmul(YOrthScoreMat[i].transpose()),
      );

      kernelX[0][i + 1] = kernelX[0][i].mmul(ITo);
      kernelX[i + 1][i + 1] = ITo.mmul(kernelX[i][i]).mmul(ITo);
    }

    let lastScoreMat = (predScoreMat[this.orthogonalComp] = kernelX[0][
      this.orthogonalComp
    ]
      .transpose()
      .mmul(YScoreMat)
      .mmul(SigmaPow));

    let lastTpPrime = lastScoreMat.transpose();
    TURegressionCoeff[this.orthogonalComp] = Matrix.inverse(
      lastTpPrime.mmul(lastScoreMat),
    )
      .mmul(lastTpPrime)
      .mmul(YScoreMat);

    this.YLoadingMat = YLoadingMat;
    this.SigmaPow = SigmaPow;
    this.YScoreMat = YScoreMat;
    this.predScoreMat = predScoreMat;
    this.YOrthLoadingVec = YOrthLoadingVec;
    this.YOrthEigen = YOrthEigen;
    this.YOrthScoreMat = YOrthScoreMat;
    this.toNorm = YOrthScoreNorm;
    this.TURegressionCoeff = TURegressionCoeff;
    this.kernelX = kernelX;
  }

  /**
   * Predicts the output given the matrix to predict.
   * @param {Matrix|Array} toPredict
   * @return {{y: Matrix, predScoreMat: Array<Matrix>, predYOrthVectors: Array<Matrix>}} predictions
   */
  predict(toPredict) {
    let KTestTrain = this.kernel.compute(toPredict, this.trainingSet);

    let temp = KTestTrain;
    KTestTrain = new Array(this.orthogonalComp + 1);
    for (let i = 0; i < this.orthogonalComp + 1; i++) {
      KTestTrain[i] = new Array(this.orthogonalComp + 1);
    }
    KTestTrain[0][0] = temp;

    let YOrthScoreVector = new Array(this.orthogonalComp);
    let predScoreMat = new Array(this.orthogonalComp);

    let i;
    for (i = 0; i < this.orthogonalComp; ++i) {
      predScoreMat[i] = KTestTrain[i][0]
        .mmul(this.YScoreMat)
        .mmul(this.SigmaPow);

      YOrthScoreVector[i] = Matrix.Matrix.sub(
        KTestTrain[i][i],
        predScoreMat[i].mmul(this.predScoreMat[i].transpose()),
      )
        .mmul(this.predScoreMat[i])
        .mmul(this.YOrthLoadingVec[i])
        .mul(Math.pow(this.YOrthEigen[i], -0.5));

      YOrthScoreVector[i] = YOrthScoreVector[i].divRowVector(this.toNorm[i]);

      let scoreMatPrime = this.YOrthScoreMat[i].transpose();
      KTestTrain[i + 1][0] = Matrix.Matrix.sub(
        KTestTrain[i][0],
        YOrthScoreVector[i]
          .mmul(scoreMatPrime)
          .mmul(this.kernelX[0][i].transpose()),
      );

      let p1 = Matrix.Matrix.sub(
        KTestTrain[i][0],
        KTestTrain[i][i].mmul(this.YOrthScoreMat[i]).mmul(scoreMatPrime),
      );
      let p2 = YOrthScoreVector[i].mmul(scoreMatPrime).mmul(this.kernelX[i][i]);
      let p3 = p2.mmul(this.YOrthScoreMat[i]).mmul(scoreMatPrime);

      KTestTrain[i + 1][i + 1] = p1.sub(p2).add(p3);
    }

    predScoreMat[i] = KTestTrain[i][0].mmul(this.YScoreMat).mmul(this.SigmaPow);
    let prediction = predScoreMat[i]
      .mmul(this.TURegressionCoeff[i])
      .mmul(this.YLoadingMat.transpose());

    return {
      prediction: prediction,
      predScoreMat: predScoreMat,
      predYOrthVectors: YOrthScoreVector,
    };
  }

  /**
   * Export the current model to JSON.
   * @return {object} - Current model.
   */
  toJSON() {
    return {
      name: 'K-OPLS',
      YLoadingMat: this.YLoadingMat,
      SigmaPow: this.SigmaPow,
      YScoreMat: this.YScoreMat,
      predScoreMat: this.predScoreMat,
      YOrthLoadingVec: this.YOrthLoadingVec,
      YOrthEigen: this.YOrthEigen,
      YOrthScoreMat: this.YOrthScoreMat,
      toNorm: this.toNorm,
      TURegressionCoeff: this.TURegressionCoeff,
      kernelX: this.kernelX,
      trainingSet: this.trainingSet,
      orthogonalComp: this.orthogonalComp,
      predictiveComp: this.predictiveComp,
    };
  }

  /**
   * Load a K-OPLS with the given model.
   * @param {object} model
   * @param {Kernel} kernel - kernel used on the model, see [ml-kernel](https://github.com/mljs/kernel).
   * @return {KOPLS}
   */
  static load(model, kernel) {
    if (model.name !== 'K-OPLS') {
      throw new RangeError(`Invalid model: ${model.name}`);
    }

    if (!kernel) {
      throw new RangeError('You must provide a kernel for the model!');
    }

    model.kernel = kernel;
    return new KOPLS(true, model);
  }
}

/**
 * OPLS loop
 * @param {Array} x a matrix with features
 * @param {Array} y an array of labels (dependent variable)
 * @param {Object} options an object with options
 * @return {Object} an object with model (filteredX: err,
    loadingsXOrtho: pOrtho,
    scoresXOrtho: tOrtho,
    weightsXOrtho: wOrtho,
    weightsPred: w,
    loadingsXpred: p,
    scoresXpred: t,
    loadingsY:)
 */
function OPLSNipals(x, y, options = {}) {
  const { numberOSC = 100 } = options;

  let X = Matrix__default.checkMatrix(x);
  let Y = Matrix__default.checkMatrix(y);

  let u = Y.getColumnVector(0);

  let diff = 1;
  let t, c, w, uNew;
  for (let i = 0; i < numberOSC && diff > 1e-10; i++) {
    w = u
      .transpose()
      .mmul(X)
      .div(
        u
          .transpose()
          .mmul(u)
          .get(0, 0),
      );
    w = w.transpose().div(norm(w));

    t = X.mmul(w).div(
      w
        .transpose()
        .mmul(w)
        .get(0, 0),
    ); // t_h paso 3

    // calc loading
    c = t
      .transpose()
      .mmul(Y)
      .div(
        t
          .transpose()
          .mmul(t)
          .get(0, 0),
      );

    // calc new u and compare with one in previus iteration (stop criterion)
    uNew = Y.mmul(c.transpose());
    uNew = uNew.div(
      c
        .transpose()
        .mmul(c)
        .get(0, 0),
    );

    if (i > 0) {
      diff =
        uNew
          .clone()
          .sub(u)
          .pow(2)
          .sum() /
        uNew
          .clone()
          .pow(2)
          .sum();
    }

    u = uNew.clone();
  }

  // calc loadings
  let p = t
    .transpose()
    .mmul(X)
    .div(
      t
        .transpose()
        .mmul(t)
        .get(0, 0),
    );

  let wOrtho = p.clone().sub(
    w
      .transpose()
      .mmul(p.transpose())
      .div(
        w
          .transpose()
          .mmul(w)
          .get(0, 0),
      )
      .mmul(w.transpose()),
  );
  wOrtho.div(norm(wOrtho));

  // orthogonal scores
  let tOrtho = X.mmul(wOrtho.transpose()).div(
    wOrtho.mmul(wOrtho.transpose()).get(0, 0),
  );

  // orthogonal loadings
  let pOrtho = tOrtho
    .transpose()
    .mmul(X)
    .div(
      tOrtho
        .transpose()
        .mmul(tOrtho)
        .get(0, 0),
    );

  // filtered data
  let err = X.clone().sub(tOrtho.mmul(pOrtho));
  return {
    filteredX: err,
    weightsXOrtho: wOrtho,
    loadingsXOrtho: pOrtho,
    scoresXOrtho: tOrtho,
    weightsXPred: w,
    loadingsXpred: p,
    scoresXpred: t,
    loadingsY: c,
  };
}

/**
 * Get total sum of square
 * @param {Array} x an array
 * @return {Number} - the sum of the squares
 */
function tss(x) {
  return Matrix.Matrix.mul(x, x).sum();
}

/**
 * Creates new OPLS (orthogonal partial latent structures) from features and labels.
 * @param {Matrix} data - matrix containing data (X).
 * @param {Array} labels - 1D Array containing metadata (Y).
 * @param {Object} [options]
 * @param {number} [options.nComp = 3] - number of latent structures computed.
 * @param {boolean} [options.center = true] - should the data be centered (subtract the mean).
 * @param {boolean} [options.scale = false] - should the data be scaled (divide by the standard deviation).
 * @param {Array} [options.cvFolds = []] - allows to provide folds as 2D array for testing purpose.
 * */

class OPLS {
  constructor(data, labels, options = {}) {
    if (data === true) {
      const opls = options;
      this.center = opls.center;
      this.scale = opls.scale;
      this.means = opls.means;
      this.meansY = opls.meansY;
      this.stdevs = opls.stdevs;
      this.stdevs = opls.stdevsY;
      this.model = opls.model;
      this.tCV = opls.tCV;
      this.tOrthCV = opls.tOrthCV;
      this.yHatCV = opls.yHatCV;
      this.mode = opls.mode;
      return;
    }

    let features = data.clone();
    // set default values
    // cvFolds allows to define folds for testing purpose
    const { nComp = 3, center = true, scale = true, cvFolds = [] } = options;

    let group;
    if (typeof labels[0] === 'number') {
      // numeric labels: OPLS regression is used
      this.mode = 'regression';
      group = Matrix.Matrix.from1DArray(labels.length, 1, labels);
    } else if (typeof labels[0] === 'string') {
      // non-numeric labels: OPLS-DA is used
      this.mode = 'discriminantAnalysis';
      group = labels;
      throw new Error('discriminant analysis is not yet supported');
    }

    // check types of features and labels
    if (features.constructor.name !== 'Matrix') {
      throw new TypeError('features must be of class Matrix');
    }
    // getting center and scale the features (all)
    this.center = center;
    if (this.center) {
      this.means = features.mean('column');
      this.meansY = group.mean('column');
    } else {
      this.stdevs = null;
    }
    this.scale = scale;
    if (this.scale) {
      this.stdevs = features.standardDeviation('column');
      this.stdevsY = group.standardDeviation('column');
    } else {
      this.means = null;
    }

    // check and remove for features with sd = 0 TODO here
    // check opls.R line 70

    let folds;
    if (cvFolds.length > 0) {
      folds = cvFolds;
    } else {
      folds = mlCrossValidation.getFolds(labels, 5);
    }

    let Q2 = [];
    this.model = [];

    this.tCV = [];
    this.tOrthCV = [];
    this.yHatCV = [];
    let oplsCV = [];

    let modelNC = [];

    // this code could be made more efficient by reverting the order of the loops
    // this is a legacy loop to be consistent with R code from MetaboMate package
    // this allows for having statistic (R2) from CV to decide wether to continue
    // with more latent structures
    let nc;
    for (nc = 0; nc < nComp; nc++) {
      let yHatk = new Matrix.Matrix(group.rows, 1);
      let tPredk = new Matrix.Matrix(group.rows, 1);
      let tOrthk = new Matrix.Matrix(group.rows, 1);
      let oplsk = [];

      let f = 0;
      for (let fold of folds) {
        let trainTest = this._getTrainTest(features, group, fold);
        let testXk = trainTest.testFeatures;
        let Xk = trainTest.trainFeatures;
        let Yk = trainTest.trainLabels;

        // determine center and scale of training set
        let dataCenter = Xk.mean('column');
        let dataSD = Xk.standardDeviation('column');

        // center and scale training set
        if (center) {
          Xk.center('column');
          Yk.center('column');
        }

        if (scale) {
          Xk.scale('column');
          Yk.scale('column');
        }

        // perform opls
        if (nc === 0) {
          oplsk[f] = OPLSNipals(Xk, Yk);
        } else {
          oplsk[f] = OPLSNipals(oplsCV[nc - 1][f].filteredX, Yk);
        }
        // store model for next component
        oplsCV[nc] = oplsk;

        let plsCV = new Matrix.NIPALS(oplsk[f].filteredX, { Y: Yk });

        // scaling the test dataset with respect to the train
        testXk.center('column', { center: dataCenter });
        testXk.scale('column', { scale: dataSD });

        let Eh = testXk;
        // removing the orthogonal components from PLS
        let scores;
        for (let idx = 0; idx < nc + 1; idx++) {
          scores = Eh.mmul(oplsCV[idx][f].weightsXOrtho.transpose()); // ok
          Eh.sub(scores.mmul(oplsCV[idx][f].loadingsXOrtho));
        }

        // prediction
        let tPred = Eh.mmul(plsCV.w.transpose());
        // this should be summed over ncomp (pls_prediction.R line 23)
        let yHat = tPred.mmul(plsCV.betas); // ok

        // adding all prediction from all folds
        for (let i = 0; i < fold.testIndex.length; i++) {
          yHatk.setRow(fold.testIndex[i], [yHat.get(i, 0)]);
          tPredk.setRow(fold.testIndex[i], [tPred.get(i, 0)]);
          tOrthk.setRow(fold.testIndex[i], [scores.get(i, 0)]);
        }
        f++;
      } // end of loop over folds

      this.tCV.push(tPredk);
      this.tOrthCV.push(tOrthk);
      this.yHatCV.push(yHatk);

      // calculate Q2y for all the prediction (all folds)
      // ROC for DA is not implemented (check opls.R line 183) TODO
      if (this.mode === 'regression') {
        let tssy = tss(group.center('column').scale('column'));
        let press = tss(group.clone().sub(yHatk));
        let Q2y = 1 - press / tssy;
        Q2.push(Q2y);
      } else if (this.mode === 'discriminantAnalysis') {
        throw new Error('discriminant analysis is not yet supported');
      }

      // calculate the R2y for the complete data
      if (nc === 0) {
        modelNC = this._predictAll(features, group);
      } else {
        modelNC = this._predictAll(
          modelNC.xRes,
          group,
          (options = { scale: false, center: false }),
        );
      }

      // adding the predictive statistics from CV
      modelNC.Q2y = Q2;
      // store the model for each component
      this.model.push(modelNC);
      // console.warn(`OPLS iteration over # of Components: ${nc + 1}`);
    } // end of loop over nc

    // store scores from CV
    let tCV = this.tCV;
    let tOrthCV = this.tOrthCV;

    let m = this.model[nc - 1];
    let XOrth = m.XOrth;
    let FeaturesCS = features.center('column').scale('column');
    let labelsCS = group.center('column').scale('column');
    let Xres = FeaturesCS.clone().sub(XOrth);
    let plsCall = new Matrix.NIPALS(Xres, { Y: labelsCS });
    let E = Xres.clone().sub(plsCall.t.mmul(plsCall.p));

    let R2x = this.model.map((x) => x.R2x);
    let R2y = this.model.map((x) => x.R2y);

    this.output = {
      Q2y: Q2,
      R2x,
      R2y,
      tPred: m.plsC.t,
      pPred: m.plsC.p,
      wPred: m.plsC.w,
      betasPred: m.plsC.betas,
      Qpc: m.plsC.q,
      tCV,
      tOrthCV,
      tOrth: m.tOrth,
      pOrth: m.pOrth,
      wOrth: m.wOrth,
      XOrth,
      yHat: m.totalPred,
      Yres: m.plsC.yResidual,
      E,
    };
  }

  /**
   * get access to all the computed elements
   * Mainly for debug and testing
   * @return {Object} output object
   */
  getLogs() {
    return this.output;
  }

  getScores() {
    let scoresX = this.tCV.map((x) => x.to1DArray());
    let scoresY = this.tOrthCV.map((x) => x.to1DArray());
    return { scoresX, scoresY };
  }

  /**
   * Load an OPLS model from JSON
   * @param {Object} model
   * @return {OPLS}
   */
  static load(model) {
    if (typeof model.name !== 'string') {
      throw new TypeError('model must have a name property');
    }
    if (model.name !== 'OPLS') {
      throw new RangeError(`invalid model: ${model.name}`);
    }
    return new OPLS(true, [], model);
  }

  /**
   * Export the current model to a JSON object
   * @return {Object} model
   */
  toJSON() {
    return {
      name: 'OPLS',
      center: this.center,
      scale: this.scale,
      means: this.means,
      stdevs: this.stdevs,
      model: this.model,
      tCV: this.tCV,
      tOrthCV: this.tOrthCV,
      yHatCV: this.yHatCV,
    };
  }

  /**
   * Predict scores for new data
   * @param {Matrix} features - a matrix containing new data
   * @param {Object} [options]
   * @param {Array} [options.trueLabel] - an array with true values to compute confusion matrix
   * @param {Number} [options.nc] - the number of components to be used
   * @return {Object} - predictions
   */
  predict(newData, options = {}) {
    let { trueLabels = [], nc = 1 } = options;
    let labels = [];
    if (trueLabels.length > 0) {
      trueLabels = Matrix.Matrix.from1DArray(trueLabels.length, 1, trueLabels);
      labels = trueLabels.clone();
    }

    let features = newData.clone();

    // scaling the test dataset with respect to the train
    if (this.center) {
      features.center('column', { center: this.means });
      if (labels.rows > 0 && this.mode === 'regression') {
        labels.center('column', { center: this.meansY });
      }
    }
    if (this.scale) {
      features.scale('column', { scale: this.stdevs });
      if (labels.rows > 0 && this.mode === 'regression') {
        labels.scale('column', { scale: this.stdevsY });
      }
    }

    let Eh = features.clone();
    // removing the orthogonal components from PLS
    let tOrth;
    let wOrth;
    let pOrth;
    let yHat;
    let tPred;

    for (let idx = 0; idx < nc; idx++) {
      wOrth = this.model[idx].wOrth.transpose();
      pOrth = this.model[idx].pOrth;
      tOrth = Eh.mmul(wOrth);
      Eh.sub(tOrth.mmul(pOrth));
      // prediction
      tPred = Eh.mmul(this.model[idx].plsC.w.transpose());
      // this should be summed over ncomp (pls_prediction.R line 23)
      yHat = tPred.mmul(this.model[idx].plsC.betas);
    }

    if (labels.rows > 0) {
      if (this.mode === 'regression') {
        let tssy = tss(labels);
        let press = tss(labels.clone().sub(yHat));
        let Q2y = 1 - press / tssy;

        return { tPred, tOrth, yHat, Q2y };
      } else if (this.mode === 'discriminantAnalysis') {
        let confusionMatrix = [];
        confusionMatrix = ConfusionMatrix.fromLabels(
          trueLabels.to1DArray(),
          yHat.to1DArray(),
        );

        return { tPred, tOrth, yHat, confusionMatrix };
      }
    } else {
      return { tPred, tOrth, yHat };
    }
  }

  _predictAll(features, labels, options = {}) {
    // cannot use the global this.center here
    // since it is used in the NC loop and
    // centering and scaling should only be
    // performed once
    const { center = true, scale = true } = options;

    if (center) {
      features.center('column');
      labels.center('column');
    }

    if (scale) {
      features.scale('column');
      labels.scale('column');
      // reevaluate tssy and tssx after scaling
      // must be global because re-used for next nc iteration
      // tssx is only evaluate the first time
      this.tssy = tss(labels);
      this.tssx = tss(features);
    }

    let oplsC = OPLSNipals(features, labels);
    let plsC = new Matrix.NIPALS(oplsC.filteredX, { Y: labels });

    let tPred = oplsC.filteredX.mmul(plsC.w.transpose());
    let yHat = tPred.mmul(plsC.betas);

    let rss = tss(labels.clone().sub(yHat));
    let R2y = 1 - rss / this.tssy;

    let xEx = plsC.t.mmul(plsC.p);
    let rssx = tss(xEx);
    let R2x = rssx / this.tssx;

    return {
      R2y,
      R2x,
      xRes: oplsC.filteredX,
      tOrth: oplsC.scoresXOrtho,
      pOrth: oplsC.loadingsXOrtho,
      wOrth: oplsC.weightsXOrtho,
      tPred: tPred,
      totalPred: yHat,
      XOrth: oplsC.scoresXOrtho.mmul(oplsC.loadingsXOrtho),
      oplsC,
      plsC,
    };
  }
  /**
   *
   * @param {*} X - dataset matrix object
   * @param {*} group - labels matrix object
   * @param {*} index - train and test index (output from getFold())
   */
  _getTrainTest(X, group, index) {
    let testFeatures = new Matrix.Matrix(index.testIndex.length, X.columns);
    let testLabels = new Matrix.Matrix(index.testIndex.length, 1);
    index.testIndex.forEach((el, idx) => {
      testFeatures.setRow(idx, X.getRow(el));
      testLabels.setRow(idx, group.getRow(el));
    });

    let trainFeatures = new Matrix.Matrix(index.trainIndex.length, X.columns);
    let trainLabels = new Matrix.Matrix(index.trainIndex.length, 1);
    index.trainIndex.forEach((el, idx) => {
      trainFeatures.setRow(idx, X.getRow(el));
      trainLabels.setRow(idx, group.getRow(el));
    });

    return {
      trainFeatures,
      testFeatures,
      trainLabels,
      testLabels,
    };
  }
}

exports.KOPLS = KOPLS;
exports.OPLS = OPLS;
exports.OPLSNipals = OPLSNipals;
exports.PLS = PLS;
